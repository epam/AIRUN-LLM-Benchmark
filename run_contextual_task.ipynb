{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from Utils.llm.api import ask_model\n",
    "from Utils.llm.config import Model, ModelProvider\n",
    "import json\n",
    "import time\n",
    "\n",
    "RESULTS_BASE_PATH = os.getenv('RESULTS_REPO_PATH')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "COMMUNICATION_PROTOCOL = \"\"\"\n",
    "## Communication Protocol:\n",
    "{\"command\": \"read-file\", \"file_path\": \"path to file\"}\n",
    "or\n",
    "{\"command\": \"file-structure\", \"file_paths\": [\"path1\", \"path2\",\"...\"]}\n",
    "or\n",
    "{\"command\": \"write-file\", \"file_path\": \"path to file\", \"content\": \"enscaped converted code\"}\n",
    "or\n",
    "{\"command\": \"end\"}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = f\"\"\"\n",
    "As an AI proficient in software engineering, particularly in Frontend development, React and Angular, \n",
    "your objective is to resolve the provided development tasks.\n",
    "\n",
    "We will exchange command messages in JSON format according to following communication protocol.\n",
    "{COMMUNICATION_PROTOCOL}\n",
    "\n",
    "Ensure that you return only valid JSON object with only one command to execute.\n",
    "Specifically, when you use the ‘write-file’ command, verify that the converted code properly transforms into a JSON string. Do not send more than one command in the message.\n",
    "\"\"\"\n",
    "\n",
    "# if you use o1 model, add {system} prompt to TASK before {objective}\n",
    "TASK = \"\"\"\n",
    "{objective}\n",
    "Outdated application is composed of the following files:\n",
    "<legacy_files_structure>\n",
    "{legacy_files_structure}\n",
    "</legacy_files_structure>\n",
    "\n",
    "Your task is to request content of each file and analyze its implementation.\n",
    "You should ask for files content by the json command.\n",
    "Example:\n",
    "{{\n",
    "    \"command\": \"read-file\",\n",
    "    \"file_path\": \"js/controllers/todo.js\" or \"app.tsx\"\n",
    "}}\n",
    "\n",
    "After getting and analyzing of all file's content - think thoroughly and *return only new file structure* of translated React application in a form of JSON command.\n",
    "Do not provide styles file, previous styles will be applied.\n",
    "Do not provide any configs.\n",
    "Example:\n",
    "{{\n",
    "    \"command\": \"file-structure\",\n",
    "    \"file_paths\": [\n",
    "        \"name1.ts\",\n",
    "        \"name2.tsx\",\n",
    "        \"...\",\n",
    "    ]\n",
    "}}\n",
    " \n",
    "After you return the file structure of the updated application, \n",
    "I will request you for each file by the file_path in the list and you should use following command to give me converted file.\n",
    "{instructions}\n",
    "\n",
    "Example:\n",
    "{{\n",
    "    \"command\": \"write-file\",\n",
    "    \"file_path\": \"path to file\"\n",
    "    \"content\": \"enscated converted code is here\"\n",
    "}}\n",
    "\n",
    "Do not add any comments in generated code and follow the instructions precisely. Once you finish the whole task, please issue the \"end\" command.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def list_files(base_path):\n",
    "    base_path = Path(base_path)\n",
    "    file_list = []\n",
    "    for file_path in base_path.rglob('*'):\n",
    "        if file_path.is_file():\n",
    "            relative_path = file_path.relative_to(base_path)\n",
    "            file_list.append(str(relative_path))\n",
    "\n",
    "    return file_list\n",
    "\n",
    "\n",
    "def run_experiment(task, model, read_files_amount, dataset_path, output_path, start_time):\n",
    "    messages = []\n",
    "    input_tokens = output_tokens = reasoning_tokens = 0\n",
    "    requests_list = [{\"role\": \"user\", \"content\": task}]\n",
    "    files_read_by_model = 0\n",
    "\n",
    "    while True:\n",
    "        if (len(requests_list) > 0):\n",
    "            messages.append(requests_list.pop())\n",
    "            print(f\"Requests left: {len(requests_list)}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if len(messages) > 0:\n",
    "            print(\"REQUEST:\")\n",
    "            print(json.dumps(messages[-1], indent=4))\n",
    "\n",
    "        answer = ask_model(messages, SYSTEM_PROMPT, model)\n",
    "        print(\"RESPONSE:\")\n",
    "        print(json.dumps(answer, indent=4))\n",
    "        command = answer[\"content\"]\n",
    "        tokens = answer[\"tokens\"]  # {'input_tokens': 168, 'output_tokens': 2031, 'reasoning_tokens': 576}\n",
    "        # Increment input_tokens, output_tokens, reasoning_tokens accordingly\n",
    "        input_tokens += tokens['input_tokens']\n",
    "        output_tokens += tokens['output_tokens']\n",
    "        reasoning_tokens += tokens.get('reasoning_tokens', 0)\n",
    "        try:\n",
    "            # Gemini always return command wrapped into json markdown block\n",
    "            # I don't find a way to prevent this behaviour, so cleaning json string before parsing it.\n",
    "            clean_content = command\n",
    "            clean_content = clean_content.strip('\\n')\n",
    "            clean_content = clean_content.strip('`')\n",
    "            clean_content = clean_content.replace('json\\n', '', 1)\n",
    "            command = json.loads(clean_content)\n",
    "        except json.JSONDecodeError as error:\n",
    "            print(error)\n",
    "            if model.provider == ModelProvider.AISTUDIO:\n",
    "                messages.append({\"role\": \"model\", \"content\": command}) # for google models\n",
    "            else:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": command})\n",
    "            requests_list.append({\"role\": \"user\", \"content\":\n",
    "                f\"\"\"Failed to parse JSON command with error: {error}.\n",
    "                Ensure that you respond with valid JSON command.\n",
    "                Provide only one JSON content with only ONE command to execute.\n",
    "                Return only valid JSON without any comments.\n",
    "                You should NEVER use markdown to wrap JSON commands.\"\"\"})\n",
    "            continue\n",
    "        if model.provider == ModelProvider.AISTUDIO:\n",
    "            messages.append({\"role\": \"model\", \"content\": json.dumps(command)})\n",
    "        else:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": json.dumps(command)})\n",
    "        if command[\"command\"] == \"end\":\n",
    "            print(\"Ending command session.\")\n",
    "            break\n",
    "        elif command[\"command\"] != \"read-file\" and files_read_by_model < read_files_amount:\n",
    "            print(f\"Error: Model should read all files first. Files read by model: {files_read_by_model}\")\n",
    "            requests_list.append({\"role\": \"user\", \"content\": f\"Please read rest {read_files_amount - files_read_by_model} files first.\"})\n",
    "        elif command[\"command\"] == \"read-file\":\n",
    "            file_path = command[\"file_path\"]\n",
    "            full_path = Path(dataset_path, file_path)\n",
    "            try:\n",
    "                with open(full_path, 'r') as file:\n",
    "                    content = file.read()\n",
    "                    requests_list.append({\"role\": \"user\", \"content\": content})\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File at {full_path} not found.\")\n",
    "            files_read_by_model += 1\n",
    "        elif command[\"command\"] == \"write-file\":\n",
    "            file_path = command[\"file_path\"]\n",
    "            full_path = Path(output_path, file_path.lstrip('/'))\n",
    "            full_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            content = command[\"content\"]\n",
    "            try:\n",
    "                with open(full_path, 'w') as file:\n",
    "                    if \".json\" in file_path:\n",
    "                        json.dump(content, file, indent=4)\n",
    "                    else:\n",
    "                        file.write(content)\n",
    "                print(f\"File written successfully at {file_path}.\")\n",
    "            except IOError as e:\n",
    "                print(f\"Failed to write file at {file_path}. Error: {e}\")\n",
    "        elif command[\"command\"] == \"file-structure\":\n",
    "            file_paths = command[\"file_paths\"]\n",
    "            for path in file_paths:\n",
    "                requests_list.append({\"role\": \"user\", \"content\": f\"Give me converted code of {path}\"})\n",
    "                print(path)\n",
    "        else:\n",
    "            reply = f\"\"\"Unknown command {command['command']}\n",
    "            Please use only supported commands:\n",
    "            {COMMUNICATION_PROTOCOL}\n",
    "            \"\"\"\n",
    "            messages.append({\"role\": \"user\", \"content\": reply})\n",
    "    end_time = int(time.time())\n",
    "    output = {\n",
    "        \"messages\": messages,\n",
    "        \"time\": end_time - start_time,\n",
    "        \"total_tokens\": {\n",
    "            \"input_tokens\": input_tokens,\n",
    "            \"output_tokens\": output_tokens,\n",
    "            \"reasoning_tokens\": reasoning_tokens,\n",
    "        }\n",
    "    }\n",
    "    messages_log = json.dumps(output, indent=4)\n",
    "    messages_log_path = Path(output_path, \"message_log.json\")\n",
    "    with open(messages_log_path, 'w') as file:\n",
    "        file.write(messages_log)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = Model.Gemini_25_Flash_0520\n",
    "current_unix_time = int(time.time())\n",
    "DATASET_PATH = f\"./Dataset/JS/ToDoApp_AngularJS\"\n",
    "OUTPUT_PATH = f\"{RESULTS_BASE_PATH}/Output/{model}/JS/contextual_experiment/translate_to_react/{current_unix_time}/\"\n",
    "\n",
    "legacy_files_list = list_files(DATASET_PATH)\n",
    "legacy_files_structure = \"\\n\".join(legacy_files_list)\n",
    "\n",
    "OBJECTIVE = \"Your task is to translate outdated AngularJS app code to recent version of React using functional components and hooks.\"\n",
    "\n",
    "INSTRUCTIONS = f\"\"\"\n",
    "Apply these instructions for translated application:\n",
    "    - Use the following libraries: TypeScript, Redux Toolkit with createSlice, and nanoid.\n",
    "    - Provide configuration of the store and provider if needed.\n",
    "    - Split the code into separate components.\n",
    "    - Optimize the code where possible.\n",
    "    - The converted code should not contain any TODOs.\n",
    "    - Return the translated code as markdown code snippets.\n",
    "    - Simply return the codebase without additional comments or explanations on how to convert it.\n",
    "\"\"\"\n",
    "\n",
    "task = TASK.format(\n",
    "    # system=SYSTEM_PROMPT,\n",
    "    objective=OBJECTIVE,\n",
    "    legacy_files_structure=legacy_files_structure,\n",
    "    instructions=INSTRUCTIONS)\n",
    "\n",
    "print(task)\n",
    "\n",
    "run_experiment(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    read_files_amount=len(legacy_files_list),\n",
    "    dataset_path=DATASET_PATH,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    start_time=current_unix_time\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = Model.Gemini_25_Flash_0520\n",
    "current_unix_time = int(time.time())\n",
    "DATASET_PATH = f\"./Dataset/JS/ToDoApp_ReactJS\"\n",
    "OUTPUT_PATH = f\"{RESULTS_BASE_PATH}/Output/{model}/JS/contextual_experiment/update_react/{current_unix_time}/\"\n",
    "legacy_files_list = list_files(DATASET_PATH)\n",
    "legacy_files_structure = \"\\n\".join(legacy_files_list)\n",
    "print(legacy_files_list, len(legacy_files_list))\n",
    "\n",
    "OBJECTIVE = \"Your task is to translate outdated React app code to modern version of React.\"\n",
    "\n",
    "INSTRUCTIONS = \"\"\"\n",
    "While updating application - follow next instructions:\n",
    "- Use the following libraries: TypeScript, React-Router, Redux Toolkit with createSlice, and nanoid.\n",
    "- Provide configuration of the store and provider if needed.\n",
    "- Split the code into separate components.\n",
    "- Optimize the code where possible.\n",
    "- The converted code should not contain any TODOs.\n",
    "- Return the translated code as markdown code snippets.\n",
    "- Simply return the codebase without additional comments or explanations on how to convert it.\n",
    "\"\"\"\n",
    "\n",
    "task = TASK.format(\n",
    "    system=SYSTEM_PROMPT,\n",
    "    objective=OBJECTIVE,\n",
    "    legacy_files_structure=legacy_files_structure,\n",
    "    instructions=INSTRUCTIONS)\n",
    "\n",
    "print(task)\n",
    "\n",
    "run_experiment(\n",
    "    task=task,\n",
    "    model=model,\n",
    "    read_files_amount=len(legacy_files_list),\n",
    "    dataset_path=DATASET_PATH,\n",
    "    output_path=OUTPUT_PATH,\n",
    "    start_time=current_unix_time\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
